---
title: "Final Project"
author: "Josh Gardner, Brody Johnson, Zach Reimers, Sara Shields-Menard"
date: "2024-07-30"
output: word_document
---

## Libraries

```{r libraries, echo=FALSE}

pacman::p_load(tidyverse, caret, earth, parallel, doParallel, mlbench, randomForest,
               tree, rpart, gbm, Cubist, partykit, httr, e1071, party, usethis, RCurl,
               pROC, MASS, glmnet, MLmetrics, pamr, klaR, mda, kernlab, modeldata)
```

## Data

```{r data}

diabetes = as.data.frame(read.csv(text = getURL('https://raw.githubusercontent.com/zachbreimers/STA6543_Final_Project/main/diabetes.csv')))
```

## Check for null and missing values

```{r check_for_null_values}

which(is.na(diabetes))
which(is.null(diabetes))
```

### Conclusion
No null or missing values in data set

## Check for predictors with near zero variances

```{r NZV}

nearZeroVar(diabetes[1:8])
```

### Conclusion
No predictors with near zero variance in data set.

## Check for skewness

```{r skewness}

apply(diabetes[1:8], 2, function(x) skewness(x))
```

### Conclusion
Several predictors exhibit a higher degree of skewness, data would benefit from pre-processing including: centering, scaling, Box-Cox transformation, and normalization.

## Train Test Split

```{r train_test_split}

set.seed(100)
train_partition = createDataPartition(diabetes[,9], p = 0.8)[[1]]

# Response split
diabetes_train  = diabetes[train_partition,9]
diabetes_test   = diabetes[-train_partition,9]

# Predictor split
x_train         = diabetes[train_partition,1:8]
x_test          = diabetes[-train_partition,1:8]
```

## Continuous Response Train Control

```{r Continuous Response ctrl}

indx = createFolds(diabetes_train, returnTrain = TRUE)
ctrl = trainControl(method = "cv", index = indx)
```

## Continuous Response Models

## Linear Regression and It's Cousins

### Linear Regression

```{r lm}

set.seed(100)

diabetes_lm = train(x = x_train, y = diabetes_train,
                    method = 'lm',
                    preProcess = c('center', 'scale', 'BoxCox', 'spatialSign'),
                    trControl = ctrl)

#diabetes_lm
summary(diabetes_lm)

diabetes_results = data.frame(obs = diabetes_test,
                              LM = predict(diabetes_lm, x_test))
```

### Partial Least Squares

```{r pls, include=FALSE}

set.seed(100)
diabetes_pls = train(x = x_train, y = diabetes_train,
                    method = 'pls',
                    tuneGrid = expand.grid(ncomp = 1:5),
                    preProcess = c('center', 'scale', 'BoxCox', 'spatialSign'),
                    trControl = ctrl)

diabetes_results$PLS = predict(diabetes_pls, x_test)
```

```{r pls_output}

#diabetes_pls
plot(diabetes_pls)
```

### PCR

```{r pcr, include=FALSE}

set.seed(100)
diabetes_pcr = train(x = x_train, y = diabetes_train,
                    method = 'pcr',
                    tuneGrid = expand.grid(ncomp = 1:9),
                    preProcess = c('center', 'scale', 'BoxCox', 'spatialSign'),
                    trControl = ctrl)

diabetes_results$PCR = predict(diabetes_pcr, x_test)
```

```{r pcr_output}

#diabetes_pcr
plot(diabetes_pcr)
```

## Shrinkage-Penalized Models

### Ridge Regression

```{r ridge, include=FALSE}

set.seed(100)

ridgeGrid = expand.grid(lambda = seq(0, .1, length = 10))

diabetes_ridge = train(x = x_train, y = diabetes_train,
                    method = 'ridge',
                    tuneGrid = ridgeGrid,
                    preProcess = c('center', 'scale', 'BoxCox', 'spatialSign'),
                    trControl = ctrl)

diabetes_results$RIDGE = predict(diabetes_ridge, x_test)
```

```{r ridge_output}

#diabetes_ridge
#names(diabetes_ridge)
#summary(diabetes_ridge)
plot(diabetes_ridge)
```

### ENET

```{r enet, include=FALSE}

set.seed(100)

enetGrid <- expand.grid(lambda = c(0, 0.01, .1, 1), 
                        fraction = seq(.05, 1, length = 20))

diabetes_enet <- train(x = x_train, y = diabetes_train,
                    method = "enet",
                    tuneGrid = enetGrid,
                    preProcess = c('center', 'scale', 'BoxCox', 'spatialSign'),
                    trControl = ctrl)

diabetes_results$ENET = predict(diabetes_enet, x_test)
```

```{r enet_output}

#diabetes_enet
#names(diabetes_enet)
#summary(diabetes_enet)
plot(diabetes_enet)
```

## NonLinear Regression Models

### Neural Net

```{r nnet, include=FALSE}

set.seed(100)

nnetGrid = expand.grid(decay = c(0, 0.01, 0.1, 1),
                       size = c(1,3,5,7),
                       bag = FALSE)

#ptm = proc.time()

diabetes_nnet = train(x = x_train, y = diabetes_train,
                  method = 'avNNet',
                  tuneGrid = nnetGrid,
                  trControl = ctrl,
                  preProcess = c('center', 'scale', 'BoxCox', 'spatialSign'),
                  linout = TRUE,
                  trace = FALSE,
                  MaxNWts = 10 * (ncol(x_train) + 1) + 10 + 1,
                  maxit = 1000,
                  allowParallel = FALSE)

#proc.time() - ptm

diabetes_results$NNET = predict(diabetes_nnet, x_test)
```

```{r nnet_output}

#diabetes_nnet
plot(diabetes_nnet)
```

### MARS

```{r MARS, include=FALSE}

set.seed(100)

diabetes_mars = train(x = x_train, y = diabetes_train,
                  method = 'earth',
                  tuneGrid = expand.grid(degree = 1, nprune = 2:38),
                  preProcess = c('center', 'scale', 'BoxCox', 'spatialSign'),
                  trControl = ctrl)

diabetes_results$MARS = predict(diabetes_mars, x_test)
```

```{r MARS_output}

#diabetes_mars
plot(diabetes_mars)

MARSimp = varImp(diabetes_mars, scale = FALSE)
plot(MARSimp)
```

### Radial SVM

```{r SVMr, include=FALSE}

set.seed(100)

diabetes_svmr = train(x = x_train, y = diabetes_train,
                  method = 'svmRadial',
                  tuneLength = 14,
                  preProcess = c('center', 'scale', 'BoxCox', 'spatialSign'),
                  trControl = ctrl)

diabetes_results$SVMr = predict(diabetes_svmr, x_test)
```

```{r SVMr_output}

#diabetes_svmr
plot(diabetes_svmr, scales = list(x = list(log = 2)))
```

### Poly SVM

```{r SVMp, include=FALSE}

set.seed(100)

svmGrid = expand.grid(degree = 1:2,
                      scale = c(0.01, 0.005, 0.0001),
                      C = 2^(-2:10))

diabetes_svmp = train(x = x_train, y = diabetes_train,
                  method = 'svmPoly',
                  tuneGrid = svmGrid,
                  preProcess = c('center', 'scale', 'BoxCox', 'spatialSign'),
                  trControl = ctrl)

diabetes_results$SVMp = predict(diabetes_svmp, x_test)
```

```{r SVMp_output}

#diabetes_svmp
plot(diabetes_svmp,
     scales = list(x = list(log = 2),
                   between = list(x = 0.5, y = 1)))
```

### KNN

```{r knn, include=FALSE}

set.seed(100)

diabetes_knn = train(x = x_train, y = diabetes_train,
                  method = 'knn',
                  tuneGrid = data.frame(k = 1:30),
                  preProcess = c('center', 'scale', 'BoxCox', 'spatialSign'),
                  trControl = ctrl)

diabetes_results$KNN = predict(diabetes_knn, x_test)
```

```{r knn_output}

#diabetes_knn
plot(diabetes_knn)
```

## Regression Trees and Rule-Based Models

### Basic Regression Tree

```{r tree, include=FALSE}

set.seed(100)

diabetes_tree = train(x = x_train, y = diabetes_train,
                  method = "rpart",
                  tuneLength = 25,
                  preProcess = c('center', 'scale', 'BoxCox', 'spatialSign'),
                  trControl = ctrl)

diabetes_results$TREE = predict(diabetes_tree, x_test)
```

```{r tree_output}

#diabetes_tree
plot(diabetes_tree, scales = list(x = list(log = 10)))

Tree = as.party(diabetes_tree$finalModel)
plot(Tree)

tree_Imp = varImp(diabetes_tree, scale = FALSE, competes = FALSE)
#tree_Imp
plot(tree_Imp)
```

### Conditional Inference Tree

```{r ctree,include=FALSE}

set.seed(100)

cGrid = data.frame(mincriterion = sort(c(.95, seq(.10, .99, length = 20))))

diabetes_ctree = train(x = x_train, y = diabetes_train,
                   method = "ctree",
                   tuneGrid = cGrid,
                   preProcess = c('center', 'scale', 'BoxCox', 'spatialSign'),
                   trControl = ctrl)

diabetes_results$CTREE = predict(diabetes_ctree, x_test)
```

```{r ctree_output}

#diabetes_ctree

plot(diabetes_ctree)

plot(diabetes_ctree$finalModel)
```

### Bagged Tree

```{r bagged_tree}

set.seed(100)

diabetes_bagged = train(x = x_train, y = diabetes_train,
                     method = "treebag",
                     nbagg = 50,
                     preProcess = c('center', 'scale', 'BoxCox', 'spatialSign'),
                     trControl = ctrl)

diabetes_bagged

diabetes_results$Bagged = predict(diabetes_bagged, x_test)
```

### Boosting

```{r boosting, include=FALSE}

set.seed(100)

gbmGrid = expand.grid( interaction.depth = seq( 1, 7, by=2 ),
                       n.trees = seq( 100, 1000, by=100 ),
                       shrinkage = c(0.01, 0.1),
                       n.minobsinnode = 10 )

diabetes_boost = train(x = x_train, y = diabetes_train,
                 method = "gbm",
                 tuneGrid = gbmGrid,
                 preProcess = c('center', 'scale', 'BoxCox', 'spatialSign'),
                 trControl = ctrl,
                 verbose = FALSE)

diabetes_results$Boosting = predict(diabetes_boost, x_test)
```

```{r boosting_output}

#diabetes_boost
plot(diabetes_boost, auto.key = list(columns = 4, lines = TRUE))
```

### Random Forest

```{r random_forest, include=FALSE}

set.seed(100)

mtryGrid = data.frame(mtry = floor(seq(1, ncol(x_train), length = 8)))

diabetes_rf = train(x = x_train, y = diabetes_train,
                method = "rf",
                tuneGrid = mtryGrid,
                ntree = 200,
                importance = TRUE,
                preProcess = c('center', 'scale', 'BoxCox', 'spatialSign'),
                trControl = ctrl)

diabetes_results$RF = predict(diabetes_rf, x_test)
```

```{r random_forest_output}

#diabetes_rf
plot(diabetes_rf)

rf_Imp = varImp(diabetes_rf, scale = FALSE)
plot(rf_Imp)
```

### Random Forest Tuned with OOB Estimates

```{r random_forest_OOB, include=FALSE}

set.seed(100)

ctrlOOB = trainControl(method = "oob")

diabetes_rfOOB = train(x = x_train, y = diabetes_train,
                method = "rf",
                tuneGrid = mtryGrid,
                ntree = 200,
                importance = TRUE,
                preProcess = c('center', 'scale', 'BoxCox', 'spatialSign'),
                trControl = ctrlOOB)

diabetes_results$RF_OOB = predict(diabetes_rfOOB, x_test)
```

```{r random_forest_OOB_output}

#diabetes_rfOOB
plot(diabetes_rfOOB)

rfOOB_Imp = varImp(diabetes_rfOOB, scale = FALSE)
plot(rfOOB_Imp)
```

### Cubist

```{r cubist, include=FALSE}

set.seed(100)

cbGrid = expand.grid(committees = c(1:10, 20, 50, 75, 100), 
                      neighbors = c(0, 1, 5, 9))

diabetes_cubist = train(x = x_train, y = diabetes_train,
                    method = "cubist",
                    tuneGrid = cbGrid,
                    preProcess = c('center', 'scale', 'BoxCox', 'spatialSign'),
                    trControl = ctrl)

diabetes_results$Cubist = predict(diabetes_cubist, x_test)
```

```{r cubist_output}

#diabetes_cubist
plot(diabetes_cubist, auto.key = list(columns = 4, lines = TRUE))

cb_Imp = varImp(diabetes_cubist, scale = FALSE)
#cb_Imp
plot(cb_Imp)
```

### Continuous Model Performance Results

```{r}

modelPerf = data.frame(rbind(OLS      = postResample(pred = diabetes_results$LM,       obs = diabetes_results$obs),
                             PLS      = postResample(pred = diabetes_results$PLS,      obs = diabetes_results$obs),
                             PCR      = postResample(pred = diabetes_results$PCR,      obs = diabetes_results$obs),
                             RIDGE    = postResample(pred = diabetes_results$RIDGE,    obs = diabetes_results$obs),
                             ENET     = postResample(pred = diabetes_results$ENET,     obs = diabetes_results$obs),
                             NNET     = postResample(pred = diabetes_results$NNET,     obs = diabetes_results$obs),
                             MARS     = postResample(pred = diabetes_results$MARS,     obs = diabetes_results$obs),
                             SVMr     = postResample(pred = diabetes_results$SVMr,     obs = diabetes_results$obs),
                             SVMp     = postResample(pred = diabetes_results$SVMp,     obs = diabetes_results$obs),
                             KNN      = postResample(pred = diabetes_results$KNN,      obs = diabetes_results$obs),
                             TREE     = postResample(pred = diabetes_results$TREE,     obs = diabetes_results$obs),
                             CTREE    = postResample(pred = diabetes_results$CTREE,    obs = diabetes_results$obs),
                             Bagged   = postResample(pred = diabetes_results$Bagged,   obs = diabetes_results$obs),
                             Boosting = postResample(pred = diabetes_results$Boosting, obs = diabetes_results$obs),
                             RF       = postResample(pred = diabetes_results$RF,       obs = diabetes_results$obs),
                             RF_OOB   = postResample(pred = diabetes_results$RF_OOF,   obs = diabetes_results$obs),
                             Cubist   = postResample(pred = diabetes_results$Cubist,   obs = diabetes_results$obs)
                             ))

modelPerf[order(modelPerf$RMSE),]
```

## Classification Response Models

## Classification Response Train Control

```{r classification response train control}

set.seed(100)
class_ctrl = trainControl(method = "LGOCV",
                     summaryFunction = twoClassSummary,
                     classProbs = TRUE,
                     savePredictions = TRUE)
```

## Convert Response Variables to Factor

```{r factor conversions}

diabetes_train_class = as.factor(make.names(diabetes_train))
diabetes_test_class = as.factor(make.names(diabetes_test))

diabetes_results$obs_class = diabetes_test_class
```

## Discriminant and Linear Classification Models

### Logistic Regression

```{r classification logistic regression}

set.seed(100)

diabetes_logistic = train(x = x_train, y = diabetes_train_class,
                          method = "glm",
                          metric = "ROC",
                          preProcess = c('center', 'scale', 'BoxCox', 'spatialSign'),
                          trControl = class_ctrl)

diabetes_logistic 

diabetes_results$Log = predict(diabetes_logistic, x_test)
diabetes_results$Log_prob = predict(diabetes_logistic, x_test, type = 'prob')[,1]
```

### Linear discriminant analysis

```{r LDA}

set.seed(100)

diabetes_lda = train(x = x_train, y = diabetes_train_class,
                     method = "lda",
                     metric = "ROC",
                     preProcess = c('center', 'scale', 'BoxCox', 'spatialSign'),
                     trControl = class_ctrl)

diabetes_lda

diabetes_results$LDA = predict(diabetes_lda, x_test)
diabetes_results$LDA_prob = predict(diabetes_lda, x_test, type = 'prob')[,1]
```

### Partial least squares discriminant analysis

```{r PLSDA}

set.seed(100)
 
diabetes_plsda = train(x = x_train, y = diabetes_train_class,
                       method = "pls",
                       metric = "ROC",
                       tuneGrid = expand.grid(.ncomp = 1:5),
                       preProcess = c('center', 'scale', 'BoxCox', 'spatialSign'),
                       trControl = class_ctrl)

diabetes_plsda

diabetes_results$PLSDA = predict(diabetes_plsda, x_test)
diabetes_results$PLSDA_prob = predict(diabetes_plsda, x_test, type = 'prob')[,1]
```

## Penalized Models & Nearest Shrunken Centroids

### Penalized Models 

```{r GLMNET}

set.seed(100) 

glmnGrid = expand.grid(.alpha = c(0, .1, .2, .4, .6, .8, 1),
                        .lambda = seq(.01, .2, length = 40))
 
diabetes_glmnet = train(x_train, y =  diabetes_train_class,
                      method = "glmnet",
                      tuneGrid = glmnGrid,
                      metric = "ROC",
                      preProcess = c('center', 'scale', 'BoxCox', 'spatialSign'),
                      trControl = class_ctrl)

#diabetes_glmnet
plot(diabetes_glmnet)
 
diabetes_results$GLMNET = predict(diabetes_glmnet, x_test)
diabetes_results$GLMNET_prob = predict(diabetes_glmnet, x_test, type = 'prob')[,1]
```

### Nearest Shrunken Centroids

```{r NSC, include=FALSE}

set.seed(100)

nscGrid = data.frame(.threshold = 0:25)

diabetes_nsc = train(x = x_train, y = diabetes_train_class,
                     method = "pam",
                     preProcess = c('center', 'scale', 'BoxCox', 'spatialSign'),
                     tuneGrid = nscGrid,
                     metric = "ROC",
                     trControl = class_ctrl)

diabetes_results$NSC = predict(diabetes_nsc, x_test)
diabetes_results$NSC_prob = predict(diabetes_nsc, x_test, type = 'prob')[,1]
```

```{r NSC_output}

#diabetes_nsc
plot(diabetes_nsc)

plot(varImp(diabetes_nsc, scale =FALSE))
```


## Non-Linear Classification Models

### Quadratic discriminant analysis

```{r qda}

set.seed(100)

diabetes_qda = train(x = x_train, y = diabetes_train_class,
                     method = "qda",
                     preProcess = c('center', 'scale', 'BoxCox', 'spatialSign'),
                     metric = "ROC",
                     trControl = class_ctrl)

diabetes_qda 

diabetes_results$QDA = predict(diabetes_qda, x_test)
diabetes_results$QDA_prob = predict(diabetes_qda, x_test, type = 'prob')[,1]
```

### Regularized discriminant analysis

```{r rda}

set.seed(100)

diabetes_rda = train(x = x_train, y = diabetes_train_class,
                     method = "rda",
                     preProcess = c('center', 'scale', 'BoxCox', 'spatialSign'), 
                     metric = "ROC",
                     trControl = class_ctrl)

diabetes_rda

diabetes_results$RDA = predict(diabetes_rda, x_test)
diabetes_results$RDA_prob = predict(diabetes_rda, x_test, type = 'prob')[,1]
```

### Mixture discriminant analysis 

```{r mda}

set.seed(100)

diabetes_mda = train(x = x_train, y = diabetes_train_class,
                     method = "mda",
                     tuneGrid = expand.grid(.subclasses = 1:8),
                     preProcess = c('center', 'scale', 'BoxCox', 'spatialSign'), 
                     metric = "ROC",
                     trControl = class_ctrl)

diabetes_mda

diabetes_results$MDA = predict(diabetes_mda, x_test)
diabetes_results$MDA_prob = predict(diabetes_mda, x_test, type = 'prob')[,1]
```

### Naïve Bayes

```{r nb}

set.seed(100)

diabetes_nb = train(x = x_train, y = diabetes_train_class,
                    method = "nb",
                    preProcess = c('center', 'scale', 'BoxCox', 'spatialSign'), 
                    metric = "ROC",
                    trControl = class_ctrl)

diabetes_nb

diabetes_results$NB = predict(diabetes_nb, x_test)
diabetes_results$NB_prob = predict(diabetes_nb, x_test, type = 'prob')[,1]
```

### K-nearest neighbors

```{r class_knn}

set.seed(100)

diabetes_class_knn = train(x = x_train, y = diabetes_train_class,
                           method = "knn",
                           metric = "ROC",
                           preProcess = c('center', 'scale', 'BoxCox', 'spatialSign'), 
                           tuneGrid = data.frame(.k =  seq(1,400, by=10)),
                           trControl = class_ctrl)

#diabetes_class_knn
plot(diabetes_class_knn)

diabetes_results$CLASS_KNN = predict(diabetes_class_knn, x_test)
diabetes_results$CLASS_KNN_prob = predict(diabetes_class_knn, x_test, type = 'prob')[,1]
```

### Neural networks

```{r class_nnet}

set.seed(100)

nnetGrid_class = expand.grid(.size = 1:15,
                             .decay = c(0, .1, 1, 2))

#maxSize_class = max(nnetGrid_class$.size)

diabetes_class_nnet <- train(x = x_train, y = diabetes_train_class,
                             method = "nnet",
                             metric = "ROC",
                             preProcess = c('center', 'scale', 'BoxCox', 'spatialSign'),  
                             tuneGrid = nnetGrid_class,
                             trace = FALSE,
                             maxit = 2000,
                             MaxNWts = 200,
                             trControl = class_ctrl)

#diabetes_class_nnet
plot(diabetes_class_nnet)

diabetes_results$CLASS_NNET = predict(diabetes_class_nnet, x_test)
diabetes_results$CLASS_NNET_prob = predict(diabetes_class_nnet, x_test, type = 'prob')[,1]
```

### Flexible discriminant analysis

```{r fda}

set.seed(100)

diabetes_FDA = train(x = x_train, y = diabetes_train_class,
                     method = "fda",
                     preProcess = c('center', 'scale', 'BoxCox', 'spatialSign'),  
                     metric = "ROC",
                     trControl = class_ctrl)

diabetes_FDA

diabetes_results$FDA = predict(diabetes_FDA, x_test)
diabetes_results$FDA_prob = predict(diabetes_FDA, x_test, type = 'prob')[,1]
```


### Support Vector Machines 

```{r class_svmr}

set.seed(100)

sigmaRangeReduced <- sigest(as.matrix(x_train))
svmRGridReduced <- expand.grid(.sigma = sigmaRangeReduced[1],
                               .C = 2^(seq(-4, 4)))

diabetes_class_svmr = train(x = x_train, y = diabetes_train_class,
                            method = "svmRadial", #svmLinear #svmPoly #Radial is common in practice
                            metric = "ROC",
                            preProcess = c('center', 'scale', 'BoxCox', 'spatialSign'), 
                            tuneGrid = svmRGridReduced,
                            fit = FALSE,
                            trControl = class_ctrl)

diabetes_class_svmr

diabetes_results$CLASS_SVMr = predict(diabetes_class_svmr, x_test)
diabetes_results$CLASS_SVMr_prob = predict(diabetes_class_svmr, x_test, type = 'prob')[,1]
```

## Classification Trees

### Classification Tree
```{r class_tree}

set.seed(100)

diabetes_class_tree = train(x = x_train, y = diabetes_train_class,
                            method = 'rpart',
                            metric = 'ROC',
                            preProcess = c('center', 'scale', 'BoxCox', 'spatialSign'),
                            tuneLength = 30,
                            trControl = class_ctrl)

#diabetes_class_tree
plot(diabetes_class_tree)

diabetes_results$CLASS_TREE = predict(diabetes_class_tree, x_test)
diabetes_results$CLASS_TREE_prob = predict(diabetes_class_tree, x_test, type = 'prob')[,1]
```

### Bagged Classification Tree

```{r bagged_class}

set.seed(100)

diabetes_class_bagged = train(x = x_train, y = diabetes_train_class,
                              method = 'treebag',
                              metric = 'ROC',
                              preProcess = c('center', 'scale', 'BoxCox', 'spatialSign'),
                              nbagg = 50,
                              trControl = class_ctrl)

diabetes_class_bagged

diabetes_results$CLASS_Bagged = predict(diabetes_class_bagged, x_test)
diabetes_results$CLASS_Bagged_prob = predict(diabetes_class_bagged, x_test, type = 'prob')[,1]
```

### Classification Boosting

```{r boosting_class}

set.seed(100)

gbmGrid_class = expand.grid( interaction.depth = seq( 1, 7, by=2 ),
                       n.trees = seq( 100, 1000, by=100 ),
                       shrinkage = c(0.01, 0.1),
                       n.minobsinnode = 10 )

diabetes_class_boosting = train(x = x_train, y = diabetes_train_class,
                                method = 'gbm',
                                metric = 'ROC',
                                preProcess = c('center', 'scale', 'BoxCox', 'spatialSign'),
                                tuneGrid = gbmGrid_class,
                                trControl = class_ctrl,
                                verbose = FALSE)

#diabetes_class_boosting
plot(diabetes_class_boosting, auto.key = list(columns = 4, lines = TRUE))

plot(varImp(diabetes_class_boosting, scale = FALSE))

diabetes_results$CLASS_Boosting = predict(diabetes_class_boosting, x_test)
diabetes_results$CLASS_Boosting_prob = predict(diabetes_class_boosting, x_test, type = 'prob')[,1]
```

### Classification Random Forest

```{r class_rf}

set.seed(100)

mtryGrid_class = data.frame(mtry = 1:8)

diabetes_class_rf = train(x = x_train, y = diabetes_train_class,
                          method = 'rf',
                          metric = 'ROC',
                          preProcess = c('center', 'scale', 'BoxCox', 'spatialSign'),
                          tuneGrid = mtryGrid_class,
                          ntree = 200,
                          importance = TRUE,
                          trControl = class_ctrl)

#diabetes_class_rf
plot(diabetes_class_rf)

diabetes_results$CLASS_RF = predict(diabetes_class_rf, x_test)
diabetes_results$CLASS_RF_prob = predict(diabetes_class_rf, x_test, type = 'prob')[,1]
```

## Model Performance and Comparison

### ROC

```{r ROC}

# ROC for logistic model
plot(roc(diabetes_results$obs_class, diabetes_results$Log_prob), col=1, lty=1, lwd=2)

# ROC for LDA
lines(roc(diabetes_results$obs_class, diabetes_results$LDA_prob), col=2, lty=2, lwd=2)

# ROC for PLSDA
lines(roc(diabetes_results$obs_class, diabetes_results$PLSDA_prob), col=3, lty=3, lwd=2)

# ROC for penalized model
lines(roc(diabetes_results$obs_class, diabetes_results$GLMNET_prob), col=4, lty=4, lwd=2)

# ROC for NSC
lines(roc(diabetes_results$obs_class, diabetes_results$NSC_prob), col=5, lty=5, lwd=2)

# ROC for Classification Tree
lines(roc(diabetes_results$obs_class, diabetes_results$CLASS_TREE_prob), col=6, lty=6, lwd=2)

# ROC for Bagged Tree
lines(roc(diabetes_results$obs_class, diabetes_results$CLASS_Bagged_prob), col=7, lty=7, lwd=2)

# ROC for Boosting
lines(roc(diabetes_results$obs_class, diabetes_results$CLASS_Boosting_prob), col=8, lty=8, lwd=2)

# ROC for Random Forest
lines(roc(diabetes_results$obs_class, diabetes_results$CLASS_RF_prob), col=9, lty=9, lwd=2)

# ROC for QDA
lines(roc(diabetes_results$obs_class, diabetes_results$QDA_prob), col=10, lty=10, lwd=2)

# ROC for RDA
lines(roc(diabetes_results$obs_class, diabetes_results$RDA_prob), col=11, lty=11, lwd=2)

# ROC for MDA
lines(roc(diabetes_results$obs_class, diabetes_results$MDA_prob), col=12, lty=12, lwd=2)

# ROC for NB
lines(roc(diabetes_results$obs_class, diabetes_results$NB_prob), col=13, lty=13, lwd=2)

# ROC for KNN
lines(roc(diabetes_results$obs_class, diabetes_results$CLASS_KNN_prob), col=14, lty=14, lwd=2)

# ROC for NNET
lines(roc(diabetes_results$obs_class, diabetes_results$CLASS_NNET_prob), col=15, lty=15, lwd=2)

# ROC for FDA
lines(roc(diabetes_results$obs_class, diabetes_results$FDA_prob), col=16, lty=16, lwd=2)

# ROC for SVMr
lines(roc(diabetes_results$obs_class, diabetes_results$CLASS_SVMr_prob), col=17, lty=17, lwd=2)

legend('bottomright',
       c('logistic', 'lda', 'plsda',
         'penalized model', 'nsc', 
         'tree', 'bagged', 'boosting',
         'rf', 'qda', 'rda', 'mda', 'nb', 
         'knn', 'nnet', 'fda', 'svmr'),
       col=1:17, lty=1:17,lwd=2)
```

### Model Accuracy

```{r kappa}

log_conf      = confusionMatrix(data = diabetes_results$Log,            reference = diabetes_results$obs_class)
LDA_conf      = confusionMatrix(data = diabetes_results$LDA,            reference = diabetes_results$obs_class)
PLSDA_conf    = confusionMatrix(data = diabetes_results$PLSDA,          reference = diabetes_results$obs_class)
GLMNET_conf   = confusionMatrix(data = diabetes_results$GLMNET,         reference = diabetes_results$obs_class)
NSC_conf      = confusionMatrix(data = diabetes_results$NSC,            reference = diabetes_results$obs_class)
tree_conf     = confusionMatrix(data = diabetes_results$CLASS_TREE,     reference = diabetes_results$obs_class)
bagged_conf   = confusionMatrix(data = diabetes_results$CLASS_Bagged,   reference = diabetes_results$obs_class)
boosting_conf = confusionMatrix(data = diabetes_results$CLASS_Boosting, reference = diabetes_results$obs_class)
rf_conf       = confusionMatrix(data = diabetes_results$CLASS_RF,       reference = diabetes_results$obs_class)
QDA_conf      = confusionMatrix(data = diabetes_results$QDA,            reference = diabetes_results$obs_class)
RDA_conf      = confusionMatrix(data = diabetes_results$RDA,            reference = diabetes_results$obs_class)
MDA_conf      = confusionMatrix(data = diabetes_results$MDA,            reference = diabetes_results$obs_class)
NB_conf       = confusionMatrix(data = diabetes_results$NB,             reference = diabetes_results$obs_class)
KNN_conf      = confusionMatrix(data = diabetes_results$CLASS_KNN,      reference = diabetes_results$obs_class)
NNET_conf     = confusionMatrix(data = diabetes_results$CLASS_NNET,     reference = diabetes_results$obs_class)
FDA_conf      = confusionMatrix(data = diabetes_results$FDA,            reference = diabetes_results$obs_class)
SVMr_conf     = confusionMatrix(data = diabetes_results$CLASS_SVMr,     reference = diabetes_results$obs_class)

model_perf_class = data.frame(rbind(log       = c(log_conf$overall[1:2],      log_conf$byClass[1:2]),
                                    LDA       = c(LDA_conf$overall[1:2],      LDA_conf$byClass[1:2]),
                                    PLSDA     = c(PLSDA_conf$overall[1:2],    PLSDA_conf$byClass[1:2]),
                                    Penalized = c(GLMNET_conf$overall[1:2],   GLMNET_conf$byClass[1:2]),
                                    NSC       = c(NSC_conf$overall[1:2],      NSC_conf$byClass[1:2]),
                                    Tree      = c(tree_conf$overall[1:2],     tree_conf$byClass[1:2]),
                                    Bagged    = c(bagged_conf$overall[1:2],   bagged_conf$byClass[1:2]),
                                    Boosting  = c(boosting_conf$overall[1:2], boosting_conf$byClass[1:2]),
                                    RF        = c(rf_conf$overall[1:2],       rf_conf$byClass[1:2]),
                                    QDA       = c(QDA_conf$overall[1:2],      QDA_conf$byClass[1:2]),
                                    RDA       = c(RDA_conf$overall[1:2],      RDA_conf$byClass[1:2]),
                                    MDA       = c(MDA_conf$overall[1:2],      MDA_conf$byClass[1:2]),
                                    NB        = c(NB_conf$overall[1:2],       NB_conf$byClass[1:2]),
                                    KNN       = c(KNN_conf$overall[1:2],      KNN_conf$byClass[1:2]),
                                    NNET      = c(NNET_conf$overall[1:2],     NNET_conf$byClass[1:2]),
                                    FDA       = c(FDA_conf$overall[1:2],      FDA_conf$byClass[1:2]),
                                    SVMr      = c(SVMr_conf$overall[1:2],     SVMr_conf$byClass[1:2])
                                    ))

model_perf_class[order(model_perf_class$Kappa, decreasing = TRUE),]
```

