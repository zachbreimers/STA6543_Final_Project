---
title: "Final Project"
author: "Josh Gardner, Brody Johnson, Zach Reimers (gpq253), Sara Shields-Menard"
date: "2024-07-30"
output: word_document
---

## Libraries

```{r libraries, echo=FALSE}

pacman::p_load(tidyverse, caret, earth, parallel, doParallel, mlbench, randomForest, tree, rpart, gbm, Cubist, partykit, httr, e1071, party, usethis, RCurl, pROC, MASS, glmnet)
```

## Data

```{r data}

diabetes = as.data.frame(read.csv(text = getURL('https://raw.githubusercontent.com/zachbreimers/STA6543_Final_Project/main/diabetes.csv')))
```

## Check for null and missing values

```{r check_for_null_values}

which(is.na(diabetes))
which(is.null(diabetes))
```

### Conclusion
No null or missing values in data set

## Check for predictors with near zero variances

```{r NZV}

nearZeroVar(diabetes[1:8])
```

### Conclusion
No predictors with near zero variance in data set.

## Check for skewness

```{r skewness}

apply(diabetes[1:8], 2, function(x) skewness(x))
```

### Conclusion
Several predictors exhibit a higher degree of skewness, data would benefit from pre-processing including: centering, scaling, Box-Cox transformation, and normalization.

## Train Test Split

```{r train_test_split}

set.seed(100)
train_partition = createDataPartition(diabetes[,9], p = 0.8)[[1]]

# Response split
diabetes_train  = diabetes[train_partition,9]
diabetes_test   = diabetes[-train_partition,9]

# Predictor split
x_train         = diabetes[train_partition,1:8]
x_test          = diabetes[-train_partition,1:8]
```

## Continuous Response Train Control

```{r Continuous Response ctrl}

indx = createFolds(diabetes_train, returnTrain = TRUE)
ctrl = trainControl(method = "cv", index = indx)
```

## Continuous Response Models

## Linear Regression and It's Cousins

### Linear Regression

```{r lm}

set.seed(100)

diabetes_lm = train(x = x_train, y = diabetes_train,
                    method = 'lm',
                    preProcess = c('center', 'scale', 'BoxCox', 'spatialSign'),
                    trControl = ctrl)

diabetes_lm
summary(diabetes_lm)

diabetes_results = data.frame(obs = diabetes_test,
                              LM = predict(diabetes_lm, x_test))
```

### Partial Least Squares

```{r pls}

set.seed(100)
diabetes_pls = train(x = x_train, y = diabetes_train,
                    method = 'pls',
                    tuneGrid = expand.grid(ncomp = 1:5),
                    preProcess = c('center', 'scale', 'BoxCox', 'spatialSign'),
                    trControl = ctrl)

diabetes_pls
plot(diabetes_pls)

diabetes_results$PLS = predict(diabetes_pls, x_test)
```

### PCR

```{r pcr}

set.seed(100)
diabetes_pcr = train(x = x_train, y = diabetes_train,
                    method = 'pcr',
                    tuneGrid = expand.grid(ncomp = 1:9),
                    preProcess = c('center', 'scale', 'BoxCox', 'spatialSign'),
                    trControl = ctrl)

diabetes_pcr
plot(diabetes_pcr)

diabetes_results$PCR = predict(diabetes_pcr, x_test)
```

## Shrinkage-Penalized Models

### Ridge Regression

```{r ridge}

set.seed(100)

ridgeGrid = expand.grid(lambda = seq(0, .1, length = 10))

diabetes_ridge = train(x = x_train, y = diabetes_train,
                    method = 'ridge',
                    tuneGrid = ridgeGrid,
                    preProcess = c('center', 'scale', 'BoxCox', 'spatialSign'),
                    trControl = ctrl)

diabetes_ridge
names(diabetes_ridge)
summary(diabetes_ridge)
plot(diabetes_ridge)

diabetes_results$RIDGE = predict(diabetes_ridge, x_test)
```

### ENET

```{r enet}

set.seed(100)

enetGrid <- expand.grid(lambda = c(0, 0.01, .1, 1), 
                        fraction = seq(.05, 1, length = 20))

diabetes_enet <- train(x = x_train, y = diabetes_train,
                    method = "enet",
                    tuneGrid = enetGrid,
                    preProcess = c('center', 'scale', 'BoxCox', 'spatialSign'),
                    trControl = ctrl)

diabetes_enet
names(diabetes_enet)
summary(diabetes_enet)
plot(diabetes_enet)

diabetes_results$ENET = predict(diabetes_enet, x_test)
```

## NonLinear Regression Models

### Neural Net

```{r nnet}

set.seed(100)

nnetGrid = expand.grid(decay = c(0, 0.01, 0.1, 1),
                       size = c(1,3,5,7),
                       bag = FALSE)

ptm = proc.time()

diabetes_nnet = train(x = x_train, y = diabetes_train,
                  method = 'avNNet',
                  tuneGrid = nnetGrid,
                  trControl = ctrl,
                  preProcess = c('center', 'scale', 'BoxCox', 'spatialSign'),
                  linout = TRUE,
                  trace = FALSE,
                  MaxNWts = 10 * (ncol(x_train) + 1) + 10 + 1,
                  maxit = 1000,
                  allowParallel = FALSE)

diabetes_nnet
plot(diabetes_nnet)

proc.time() - ptm

diabetes_results$NNET = predict(diabetes_nnet, x_test)
```

### MARS

```{r MARS}

set.seed(100)

diabetes_mars = train(x = x_train, y = diabetes_train,
                  method = 'earth',
                  tuneGrid = expand.grid(degree = 1, nprune = 2:38),
                  preProcess = c('center', 'scale', 'BoxCox', 'spatialSign'),
                  trControl = ctrl)

diabetes_mars
plot(diabetes_mars)

MARSimp = varImp(diabetes_mars, scale = FALSE)
plot(MARSimp)

diabetes_results$MARS = predict(diabetes_mars, x_test)
```

### Radial SVM

```{r SVMr}

set.seed(100)

diabetes_svmr = train(x = x_train, y = diabetes_train,
                  method = 'svmRadial',
                  tuneLength = 14,
                  preProcess = c('center', 'scale', 'BoxCox', 'spatialSign'),
                  trControl = ctrl)

diabetes_svmr
plot(diabetes_svmr, scales = list(x = list(log = 2)))

diabetes_results$SVMr = predict(diabetes_svmr, x_test)
```

### Poly SVM

```{r SVMp}

set.seed(100)

svmGrid = expand.grid(degree = 1:2,
                      scale = c(0.01, 0.005, 0.0001),
                      C = 2^(-2:10))

diabetes_svmp = train(x = x_train, y = diabetes_train,
                  method = 'svmPoly',
                  tuneGrid = svmGrid,
                  preProcess = c('center', 'scale', 'BoxCox', 'spatialSign'),
                  trControl = ctrl)

diabetes_svmp
plot(diabetes_svmp,
     scales = list(x = list(log = 2),
                   between = list(x = 0.5, y = 1)))

diabetes_results$SVMp = predict(diabetes_svmp, x_test)
```

### KNN

```{r knn}

set.seed(100)

diabetes_knn = train(x = x_train, y = diabetes_train,
                  method = 'knn',
                  tuneGrid = data.frame(k = 1:30),
                  preProcess = c('center', 'scale', 'BoxCox', 'spatialSign'),
                  trControl = ctrl)

diabetes_knn
plot(diabetes_knn)

diabetes_results$KNN = predict(diabetes_knn, x_test)
```

## Regression Trees and Rule-Based Models

### Basic Regression Tree

```{r tree}

set.seed(100)

diabetes_tree = train(x = x_train, y = diabetes_train,
                  method = "rpart",
                  tuneLength = 25,
                  preProcess = c('center', 'scale', 'BoxCox', 'spatialSign'),
                  trControl = ctrl)

diabetes_tree
plot(diabetes_tree, scales = list(x = list(log = 10)))

Tree = as.party(diabetes_tree$finalModel)
plot(Tree)

tree_Imp = varImp(diabetes_tree, scale = FALSE, competes = FALSE)
tree_Imp
plot(tree_Imp)

diabetes_results$TREE = predict(diabetes_tree, x_test)
```

### Conditional Inference Tree

```{r ctree}

set.seed(100)

cGrid <- data.frame(mincriterion = sort(c(.95, seq(.10, .99, length = 20))))

diabetes_ctree = train(x = x_train, y = diabetes_train,
                   method = "ctree",
                   tuneGrid = cGrid,
                   preProcess = c('center', 'scale', 'BoxCox', 'spatialSign'),
                   trControl = ctrl)

diabetes_ctree

plot(diabetes_ctree)

plot(diabetes_ctree$finalModel)

diabetes_results$CTREE = predict(diabetes_ctree, x_test)
```

### Bagged Tree

```{r bagged_tree}

set.seed(100)

diabetes_bagged = train(x = x_train, y = diabetes_train,
                     method = "treebag",
                     nbagg = 50,
                     preProcess = c('center', 'scale', 'BoxCox', 'spatialSign'),
                     trControl = ctrl)

diabetes_bagged

diabetes_results$Bagged <- predict(diabetes_bagged, x_test)
```

### Boosting

```{r boosting}

set.seed(100)

gbmGrid = expand.grid( interaction.depth = seq( 1, 7, by=2 ),
                       n.trees = seq( 100, 1000, by=100 ),
                       shrinkage = c(0.01, 0.1),
                       n.minobsinnode = 10 )

diabetes_boost = train(x = x_train, y = diabetes_train,
                 method = "gbm",
                 tuneGrid = gbmGrid,
                 preProcess = c('center', 'scale', 'BoxCox', 'spatialSign'),
                 trControl = ctrl,
                 verbose = FALSE)

diabetes_boost
plot(diabetes_boost, auto.key = list(columns = 4, lines = TRUE))

diabetes_results$Boosting <- predict(diabetes_boost, x_test)
```

### Random Forest

```{r random_forest}

set.seed(100)

mtryGrid <- data.frame(mtry = floor(seq(1, ncol(x_train), length = 8)))

diabetes_rf <- train(x = x_train, y = diabetes_train,
                method = "rf",
                tuneGrid = mtryGrid,
                ntree = 200,
                importance = TRUE,
                preProcess = c('center', 'scale', 'BoxCox', 'spatialSign'),
                trControl = ctrl)

diabetes_rf
plot(diabetes_rf)

rf_Imp <- varImp(diabetes_rf, scale = FALSE)
rf_Imp

diabetes_results$RF <- predict(diabetes_rf, x_test)
```

### Random Forest Tuned with OOB Estimates

```{r random_forest_OOB}

set.seed(100)

ctrlOOB <- trainControl(method = "oob")

diabetes_rfOOB = train(x = x_train, y = diabetes_train,
                method = "rf",
                tuneGrid = mtryGrid,
                ntree = 200,
                importance = TRUE,
                preProcess = c('center', 'scale', 'BoxCox', 'spatialSign'),
                trControl = ctrlOOB)

diabetes_rfOOB
plot(diabetes_rfOOB)

rfOOB_Imp <- varImp(diabetes_rfOOB, scale = FALSE)
rfOOB_Imp

diabetes_results$RF_OOB <- predict(diabetes_rfOOB, x_test)
```

### Cubist

```{r cubist}

set.seed(100)

cbGrid = expand.grid(committees = c(1:10, 20, 50, 75, 100), 
                      neighbors = c(0, 1, 5, 9))

diabetes_cubist = train(x = x_train, y = diabetes_train,
                    method = "cubist",
                    tuneGrid = cbGrid,
                    preProcess = c('center', 'scale', 'BoxCox', 'spatialSign'),
                    trControl = ctrl)

diabetes_cubist
plot(diabetes_cubist, auto.key = list(columns = 4, lines = TRUE))

cb_Imp <- varImp(diabetes_cubist, scale = FALSE)
cb_Imp
plot(cb_Imp)

diabetes_results$Cubist <- predict(diabetes_cubist, x_test)
```

### Continuous Model Performance Results

```{r}

modelPerf = data.frame(rbind(OLS      = postResample(pred = diabetes_results$LM,       obs = diabetes_results$obs),
                             PLS      = postResample(pred = diabetes_results$PLS,      obs = diabetes_results$obs),
                             PCR      = postResample(pred = diabetes_results$PCR,      obs = diabetes_results$obs),
                             RIDGE    = postResample(pred = diabetes_results$RIDGE,    obs = diabetes_results$obs),
                             ENET     = postResample(pred = diabetes_results$ENET,     obs = diabetes_results$obs),
                             NNET     = postResample(pred = diabetes_results$NNET,     obs = diabetes_results$obs),
                             MARS     = postResample(pred = diabetes_results$MARS,     obs = diabetes_results$obs),
                             SVMr     = postResample(pred = diabetes_results$SVMr,     obs = diabetes_results$obs),
                             SVMp     = postResample(pred = diabetes_results$SVMp,     obs = diabetes_results$obs),
                             KNN      = postResample(pred = diabetes_results$KNN,      obs = diabetes_results$obs),
                             TREE     = postResample(pred = diabetes_results$TREE,     obs = diabetes_results$obs),
                             CTREE    = postResample(pred = diabetes_results$CTREE,    obs = diabetes_results$obs),
                             Bagged   = postResample(pred = diabetes_results$Bagged,   obs = diabetes_results$obs),
                             Boosting = postResample(pred = diabetes_results$Boosting, obs = diabetes_results$obs),
                             RF       = postResample(pred = diabetes_results$RF,       obs = diabetes_results$obs),
                             RF_OOB   = postResample(pred = diabetes_results$RF_OOF,   obs = diabetes_results$obs),
                             Cubist   = postResample(pred = diabetes_results$Cubist,   obs = diabetes_results$obs)
                             ))

modelPerf[order(modelPerf$RMSE),]
```


## Classification Response Models

## Classification Response Train Control

```{r classification response train control}

set.seed(100)
class_ctrl <- trainControl(method = "LGOCV",
                     summaryFunction = twoClassSummary,
                     classProbs = TRUE,
                     savePredictions = TRUE)
```

## Convert Response Variables to Factor

```{r factor conversions}

diabetes_train_class = as.factor(diabetes_train)
diabetes_test_class = as.factor(diabetes_test)
```

## Discriminant and Linear Classification Models

### Logistic Regression

```{r classification logistic regression}
set.seed(100)

diabetes_logistic = train(x = x_train, y = diabetes_train,
                          method = "glm",
                          metric = "ROC",
                          preProcess = c('center', 'scale', 'BoxCox', 'spatialSign'),
                          trControl = class_ctrl)

diabetes_logistic 


diabetes_results$Log = predict(diabetes_logistic, x_test)
diabetes_results$Log_prob = predict(diabetes_logistic, x_test, type = 'prob')[,1]

```

### Linear discriminant analysis

```{r LDA}
set.seed(100)

diabetes_lda = train(x = x_train_trans, y = diabetes_train,
                     method = "lda",
                     metric = "ROC",
                     preProcess = c('center', 'scale', 'BoxCox', 'spatialSign'),
                     trControl = class_ctrl)

diabetes_lda

diabetes_results$LDA <- predict(diabetes_lda, x_test)
```

### Partial least squares discriminant analysis

```{r}
 set.seed(100)
 diabetes_plsda <- train(x = x_train_trans,
 y = diabetes_train,
 method = "pls",
 tuneGrid = expand.grid(.ncomp = 1:5),
 trControl = class_ctrl)

 diabetes_plsda #ncomp=4 has largest area under curve (ROC=0.81045)

 ### Save the test set results in a data frame  
 diabetes_results$PLSDA <- predict(diabetes_plsda, x_test)

```


## Penalized Models & Nearest Shrunken Centroids

### Penalized Models 

```{r}
 glmnGrid <- expand.grid(.alpha = c(0, .1, .2, .4, .6, .8, 1),
 .lambda = seq(.01, .2, length = 40))
 set.seed(100)
 
 diabetes_glmn <- train(x_train_trans,
 y =  diabetes_train,
 method = "glmnet",
 tuneGrid = glmnGrid,
 metric = "ROC",
 trControl = class_ctrl)
 plot(diabetes_glmn)
 
 ### Save the test set results in a data frame  
 diabetes_results$GLMN <- predict(diabetes_glmn, x_test)
```

### Nearest Shrunken Centroids

```{r}
nscGrid <- data.frame(.threshold = 0:25) #tuning parameter
diabetes_nsc <- train(x = x_train_trans,
 y = diabetes_train,
method = "pam",
 preProc = c("center", "scale"),
 tuneGrid = nscGrid,
 metric = "ROC",
trControl = class_ctrl)

diabetes_nsc
plot(diabetes_nsc)

#variale importance 
plot(varImp(diabetes_nsc, scale =FALSE))


 ### Save the test set results in a data frame  
 diabetes_results$NSC <- predict(diabetes_nsc, x_test)
```


